{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Using the YOLOv8s Stock Market Future Prediction Model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "d:\\OneDrive\\myproject\\stockmarket-pattern-detection-yolov8\\.venv\\Lib\\site-packages\\tqdm\\auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "0: 256x640 1 down, 213.0ms\n",
      "Speed: 3.3ms preprocess, 213.0ms inference, 2.0ms postprocess per image at shape (1, 3, 256, 640)\n",
      "Detected boxes: ultralytics.engine.results.Boxes object with attributes:\n",
      "\n",
      "cls: tensor([0.])\n",
      "conf: tensor([0.3663])\n",
      "data: tensor([[9.0943e+02, 1.4588e+02, 9.8057e+02, 2.4901e+02, 3.6629e-01, 0.0000e+00]])\n",
      "id: None\n",
      "is_track: False\n",
      "orig_shape: (883, 2475)\n",
      "shape: torch.Size([1, 6])\n",
      "xywh: tensor([[944.9972, 197.4489,  71.1406, 103.1286]])\n",
      "xywhn: tensor([[0.3818, 0.2236, 0.0287, 0.1168]])\n",
      "xyxy: tensor([[909.4269, 145.8846, 980.5674, 249.0132]])\n",
      "xyxyn: tensor([[0.3674, 0.1652, 0.3962, 0.2820]])\n",
      "Rendered image is not in the correct format, drawing manually.\n"
     ]
    }
   ],
   "source": [
    "import cv2\n",
    "import numpy as np\n",
    "from ultralyticsplus import YOLO, render_result\n",
    "\n",
    "# Load the YOLO model\n",
    "model = YOLO('foduucom/stockmarket-future-prediction')\n",
    "\n",
    "# Path to the image file\n",
    "image_path = r'images/BTCUSD_2024-04-17_09-36-41.png'\n",
    "image = cv2.imread(image_path)\n",
    "\n",
    "if image is None:\n",
    "    print(\"Error: Image not found.\")\n",
    "else:\n",
    "    # Perform inference on the loaded image\n",
    "    results = model.predict(image)\n",
    "\n",
    "    # Check for detections and try to render them\n",
    "    print(\"Detected boxes:\", results[0].boxes)\n",
    "    if results[0].boxes:\n",
    "        # Attempt to render the result using the built-in render function\n",
    "        rendered_image = render_result(model=model, image=image, result=results[0])\n",
    "        \n",
    "        # Check if rendered image is a valid numpy array\n",
    "        if isinstance(rendered_image, np.ndarray):\n",
    "            # Display the rendered image if it's valid\n",
    "            cv2.imshow('YOLOv8 Prediction', rendered_image)\n",
    "            cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "            cv2.destroyAllWindows()\n",
    "        else:\n",
    "            print(\"Rendered image is not in the correct format, drawing manually.\")\n",
    "            \n",
    "            # Manually draw bounding boxes and labels on the image\n",
    "            for box in results[0].boxes.data:\n",
    "                x1, y1, x2, y2 = int(box[0]), int(box[1]), int(box[2]), int(box[3])\n",
    "                conf = box[4]\n",
    "                cls = int(box[5])  # Assuming class labels are encoded as integers\n",
    "\n",
    "                # Retrieve class label using the class index\n",
    "                label = results[0].names.get(cls, str(cls))\n",
    "                label_with_conf = f\"{label} {conf:.2f}\"\n",
    "\n",
    "                # Draw the bounding box on the image\n",
    "                cv2.rectangle(image, (x1, y1), (x2, y2), (0, 255, 0), 2)\n",
    "                \n",
    "                # Put the class label with confidence score near the bounding box\n",
    "                cv2.putText(image, label_with_conf, (x1, y1 - 10), cv2.FONT_HERSHEY_SIMPLEX, 0.5, (0, 255, 0), 2)\n",
    "\n",
    "            # Show the manually annotated image\n",
    "            cv2.imshow('Detected Trends', image)\n",
    "            cv2.waitKey(0)  # Wait for a key press to close the window\n",
    "            cv2.destroyAllWindows()\n",
    "    else:\n",
    "        print(\"No detections.\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
